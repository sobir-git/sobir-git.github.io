<!DOCTYPE html>
<html lang="english">
<head>
          <title>Raw Blog - Hypothesis Testing</title>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Raw Blog Full Atom Feed" />
        <link href="/feeds/misc.atom.xml" type="application/atom+xml" rel="alternate" title="Raw Blog Categories Atom Feed" />

        <link rel="stylesheet" href="/theme/css/rdark.css" />
        <link rel="stylesheet" type="text/css" href="/theme/css/main.css" />
        <link href="/" type="application/atom+xml" rel="alternate" title="Raw Blog ATOM Feed" /><!--[if IE]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-8WVZ6PMB17"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-8WVZ6PMB17');
        </script>

        <!-- Using MathJax, with the delimiters $ -->
        <!-- Conflict with pygments for the .mo and .mi -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          "HTML-CSS": {
          styles: {
          ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
          },
          tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']],processEscapes: true}
          });
        </script>

        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>






</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">Raw Blog</a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li class="active"><a href="/category/misc.html">misc</a></li>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="/hypothesis-testing.html" rel="bookmark"
         title="Permalink to Hypothesis Testing">Hypothesis Testing</a></h2>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2021-05-01T00:00:00+03:00">
      Sat 01 May 2021
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="/author/sobir-bobiev.html">Sobir Bobiev</a>
    </address>
    <div class="category">
        Category: <a href="/category/misc.html">misc</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>The following are my notes when I studied <a href="https://www.statlect.com/fundamentals-of-statistics/hypothesis-testing">this chapter</a> on hypothesis testing.</p>
<p>First we define what is a <strong>statistical model</strong>.</p>
<h3>Statistical Models</h3>
<p>The term didn't catch attention, as if I already knew it. Perhaps true. I know both words in isolation, and I've seen both together. But here follows the formal definition.</p>
<p>Given an unknown distribution. Assume we only have some samples from it. Of course we cannot characterize the original distribution just from a finite number of samples. We can only infer some properties of it given particular circumstances. For example we assume that it belongs to a certain class of probability distributions. If we assume it is a normal distribution, then we go further and estimate its mean and variance, or make a probabilistic statements about it. </p>
<p>So, the class which we assumed the unknown distributions belongs to is called our <em>statistical model</em>. We could have modeled it correctly, in which case we say our model is <strong>correctly specified</strong>. Otherwise, it is <strong>mis-specified</strong>.</p>
<h3>Statistical Inference</h3>
<p>A statistical inference is a statement about the population from a given sample. They are based on a given sample and the statistical model. A statistical inference has the form of model restriction. Let the original model be $\Phi$. Then the statistical inference can talk about a subset of model, $\Phi_R$, in one of the following forms: (a) the unknown distribution belongs to $\Phi_X$, or (b) the unknown distribution does not belong to $\Phi_X$.</p>
<ul>
<li>
<p>In <strong>hypothesis testing</strong>, first such a model restriction is proposed, then the choice is made whether to accept the restriction or reject it.</p>
</li>
<li>
<p>In <strong>estimation</strong>, a restriction is to be chosen with certain level of certainty.</p>
</li>
<li>
<p>In <strong>Bayesian inference</strong>, we already have a subjective restriction, and it is updated with the knowledge of the given sample.</p>
</li>
</ul>
<p>What is a <strong>sample</strong>? A realization of a random vector.</p>
<h3>Hypothesis testing</h3>
<p>Quoting from the book:</p>
<blockquote>
<p>Hypothesis testing is a method of making statistical inferences by establishing an hypothesis, called null hypothesis, and using some data to decide whether to reject or not to reject the hypothesis.</p>
</blockquote>
<p>For parametric models, let $\Theta \subseteq \mathbb{R}^p$ be the parameter space. Let the true parameter of the unknown distribution be $\theta_0$. Let the chosen parameter restriction be $\Theta_R$. Then the <strong>null hypothesis</strong> is defined as
$$H_0: \theta_0 \in \Theta_R$$</p>
<p>And the <strong>alternative hyptothesis</strong> is defined as
$$H_1: \theta_0 \in \Theta_R^c$$</p>
<h4>Types of errors</h4>
<p>Whether the null hypothesis is accepted or rejected, the decision may be wrong. Two types of errors exist:
1. Reject the null hypothesis when it is indeed true, called <strong>Type I error</strong>.
2. Do not reject the null hypothesis when it is indeed false, called <strong>Type II error</strong>.</p>
<p>~ (how can one not confuse these two terms? my trick is to think <em>conservatively</em>: rejecting the true null hypothesis, which is often deemed as default is the main error, hence type I.)</p>
<h4>Critical region</h4>
<p>Is a subset of support where the null hypothesis is rejected when the sample observed happens to be from there. For hypothesis tests about the mean, the critical region could be a value above or below which has very low probability and the presence of the sample in it is a strong evidence agains the null hypothesis.</p>
<blockquote>
<p>Q: How do we choose critical region? </p>
<p>We can choose whatever, but the hypothesis test results can be wrong. I suppose, the "smaller" the critical region we choose, the more likely the test result will stick with null hypothesis. </p>
</blockquote>
<p>From the book:</p>
<blockquote>
<p>The critical region is often defined implicitly through a <strong>test statistic</strong> and a <strong>critical region</strong> for the test statistic. </p>
</blockquote>
<h4>Test statistic</h4>
<p>Is a function of sample (a quantity derived from the sample). Hence, it is a random variable. Its critical region is a subset of $\mathbb{R}$. Once one draws its critical region, it implies a certain critical region for the sample as well. The test will be based on test statistic:
$$
\text{test statistic is in critical region} \Rightarrow \text{sample is in critical region} \Rightarrow H_0 \text{ is rejected} 
$$$$
\text{test statistic not in critical region} \Rightarrow \text{sample not in critical region} \Rightarrow H_0 \text{ is not rejected}
$$</p>
<blockquote>
<p>Q: Why use test statistic when defining a critical region is enough?</p>
<p>I suppose, usually the test statistic is much easier to reason about and define a reasonable critical region. On the other hand, defining a critical region for the sample is impractical as you have multiple samples and each can be vectors.</p>
</blockquote>
<h4>Power of test</h4>
<p>Power of a test is the probability of rejecting the null hypothesis when, in fact, it is false. Power is a number between 0 and 1. Thus, the power of 1 indicates that the test is "powerful", i.e. it rejects the null hypothesis whenever it is false. In other terms, it indicates immunity from Type II error. 
Yes, it would be great to know the power of your test. So, how? </p>
<h4>Power function</h4>
<p>This is the generalization of the notion of power of test. While power of test is just a quantity, the power function is defined on every possible parameter $\theta$, in case of parametric tests. 
$$
\pi(\theta) = P(\text{sample falls in critical region} | \text{true distribution parameter is } \theta)
$$</p>
<p>More on power function <a href="https://www.statlect.com/glossary/power-function">here</a> that has a simple example included.
Knowing the power function of your test is great. But how can you derive?</p>
<!-- 
..graphviz dot
digraph {
    A [label="King Arthur"]
    B [label="Sir Bedevere the Wise"]
    L [label="Sir Lancelot the Brave"]
    A -> B
    A -> L
    B -> L [constraint=false]
}
 -->
  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>